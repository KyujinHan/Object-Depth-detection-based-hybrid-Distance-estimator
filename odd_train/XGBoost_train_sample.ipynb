{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @author: ODD team\n",
    "# XGBoost model- this is adapted\n",
    "  \n",
    "#### You cau use this form about training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Module\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from custom_datasets import CustomDataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.metrics import make_scorer\n",
    "#define your own mse and set greater_is_better=False\n",
    "mse = make_scorer(mean_squared_error,greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train valid test set\n",
    "df_train = pd.read_csv('../datasets/kitti_train_1.csv')\n",
    "df_valid = pd.read_csv('../datasets/kitti_valid_1.csv')\n",
    "df_test = pd.read_csv('../datasets/kitti_test_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.drop(['filename', 'weather','depth_min'], axis=1)\n",
    "valid = df_valid.drop(['filename', 'weather','depth_min'], axis=1)\n",
    "test = df_test.drop(['filename', 'weather','depth_min'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "le=LabelEncoder()\n",
    "tr=le.fit_transform(train['class'].values)\n",
    "vv=le.fit_transform(valid['class'].values)\n",
    "ts=le.fit_transform(test['class'].values)\n",
    "\n",
    "train['class']=tr\n",
    "valid['class']=vv\n",
    "test['class']=ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['zloc'] < 90].reset_index(drop=True)\n",
    "valid = valid[valid['zloc'] < 90].reset_index(drop=True)\n",
    "test = pd.DataFrame(test[test['zloc']< 90]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_train = train.loc[:, train.columns != 'zloc']\n",
    "y_train = train.loc[:, train.columns == 'zloc']\n",
    "\n",
    "X_valid = valid.loc[:, valid.columns != 'zloc']\n",
    "y_valid = valid.loc[:, valid.columns == 'zloc']\n",
    "\n",
    "X_test = test.loc[:, test.columns != 'zloc']\n",
    "y_test = test.loc[:, test.columns == 'zloc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalerX = StandardScaler().fit(X_train)\n",
    "#scalery = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= scalerX.transform(X_train)\n",
    "#y_train_scale = scalery.transform(y_train)\n",
    "\n",
    "X_valid= scalerX.transform(X_valid)\n",
    "#y_valid_scale = scalery.transform(y_valid)\n",
    "\n",
    "X_test= scalerX.transform(X_test)\n",
    "#y_test_scale = scalery.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서화\n",
    "#X_train = xgb.DMatrix(X_train_scale)\n",
    "#y_train = xgb.DMatrix(y_train.values)\n",
    "\n",
    "#X_valid = xgb.DMatrix(X_valid_scale)\n",
    "#y_valid = xgb.DMatrix(y_valid.values)\n",
    "\n",
    "#X_test = xgb.DMatrix(X_test_scale)\n",
    "#y_test = xgb.DMatrix(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./weights', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this is parameter tuning result\n",
    "\"\"\"kfol=KFold(n_splits=3,random_state=2022,shuffle=True)\n",
    "xgb1 = xgb.XGBRegressor( tree_method='gpu_hist')\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "parameters = {\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [0.01,1e-5], \n",
    "              'max_depth': [3,5,7,9],\n",
    "              'min_child_weight': [1,3,4,5],\n",
    "              'subsample': [0.6,0.7,0.8,1],\n",
    "              'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "              'n_estimators': [100,200,500,750,1000]\n",
    "              #'gamma':[i/10.0 for i in range(0,5)],\n",
    "              #'reg_lambda':[1,0.9,0.8,0.7,0],\n",
    "              #'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05, 0.1, 1],\n",
    "              }\n",
    "\"\"\"\n",
    "# another parameter tuning\n",
    "\"\"\"\n",
    "parameters={\n",
    "    'n_estimators': [100,200,500,750,1000],\n",
    "    'max_depth': [3,5,7,9],\n",
    "    'min_child_weight': [1,3,5],\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05, 0.1, 1],\n",
    "    'learning_rate': [0.01, 0.02, 0.05, 0.1]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "parameters= {'colsample_bytree': [0.9], \n",
    "              'learning_rate': [0.01], \n",
    "              'max_depth': [9], \n",
    "              'min_child_weight': [3], \n",
    "              'n_estimators': [1000], \n",
    "              'objective': ['reg:squarederror'], \n",
    "              'subsample': [0.7],\n",
    "              'gamma':[i/10.0 for i in range(0,5)],\n",
    "              'reg_lambda':[1,0.9,0.8,0.7,0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05, 0.1, 1],\n",
    "              }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Grid Search, we can get params tuning\n",
    "\"\"\"\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = kfol,\n",
    "                        n_jobs = 3,\n",
    "                        verbose=0\n",
    "                        )                     \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the grid search and print the result\n",
    "\"\"\"\n",
    "xgb_grid.fit(X_train,y_train,early_stopping_rounds=20,eval_metric='rmse',eval_set=[(X_valid,y_valid)],verbose=0)\n",
    "\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(xgb_grid.best_score_)\n",
    "#print(xgb_grid.best_params_)\n",
    "\n",
    "### 5/5 \n",
    "# best parameter\n",
    "bestparm={'colsample_bytree': 0.9,\n",
    "          'gamma': 0.3,\n",
    "          'learning_rate': 0.01,\n",
    "          'max_depth': 9,\n",
    "          'min_child_weight': 3,\n",
    "          'n_estimators': 1000,\n",
    "          'objective': 'reg:squarederror',\n",
    "          'reg_alpha': 1,\n",
    "          'reg_lambda': 0.9,\n",
    "          'subsample': 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "best_params= {'colsample_bytree': 0.9, \n",
    "              'learning_rate': 0.01, \n",
    "              'max_depth': 9, \n",
    "              'min_child_weight': 3, \n",
    "              'n_estimators': 1000, \n",
    "              'objective': 'reg:squarederror', \n",
    "              'subsample': 0.7}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data to fit the model format\n",
    "d_train=xgb.DMatrix(data=X_train,label=y_train)\n",
    "d_valid=xgb.DMatrix(data=X_valid,label=y_valid)\n",
    "wlist=[(d_train,'train'),(d_valid,'eval')]\n",
    "#best_params=xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the baseline_train the model\n",
    "model = xgb.train(params=bestparm,\n",
    "                  dtrain=d_train,\n",
    "                  #eval_metric='mae',\n",
    "                  evals=wlist,\n",
    "                  num_boost_round=5000\n",
    "                  #tree_method='gpu_hist'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the test set\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to the format\n",
    "d_test=xgb.DMatrix(data=X_test,label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict result\n",
    "preds= model.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract information by metric\n",
    "def testing(pred,y):\n",
    "    sums1=[]\n",
    "    sums2=[]\n",
    "    for i in range(len(preds)):\n",
    "        sqr=(float(pred[i])-float(y.loc[i]))**2\n",
    "        abs1=abs(float(pred[i])-float(y.loc[i]))\n",
    "        sums1.append(sqr)\n",
    "        sums2.append(abs1)\n",
    "        \n",
    "        \n",
    "    rmse=(sum(sums1)/len(preds))**0.5\n",
    "    mae= sum(sums2)/len(preds)\n",
    "    return rmse,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the test result\n",
    "print('rmse =', testing(preds,y_test)[0])\n",
    "print('mae =', testing(preds,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9f122e37c82151bf9f34d3eff46fea91e08eb65de67b9d89caea98024846b0d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

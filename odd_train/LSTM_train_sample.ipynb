{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xXp-L947DlL"
   },
   "source": [
    "@ author: ODD_team\n",
    "\n",
    "#Distance Estimator\n",
    "To estimate the real distance(unit: meter) of the object\n",
    "\n",
    "__Input__: Bounding box coordinates(xmin, ymin, xmax, ymax)   \n",
    "__Output__: 3D location z of carmera coordinates(z_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LiXtU2475cb"
   },
   "source": [
    "## Load Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4GISwk4884Q"
   },
   "outputs": [],
   "source": [
    "# import module\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "#import category_encoders as ce\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from custom_datasets import CustomDataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd to ./weights\n",
    "os.makedirs('./weights', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJxQzId_79SS"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data set\n",
    "df_train = pd.read_csv('../datasets/iou_train.csv')\n",
    "df_valid = pd.read_csv('../datasets/iou_valid.csv')\n",
    "df_test = pd.read_csv('../datasets/iou_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the z_loc values\n",
    "df_train['zloc'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = df_train[df_train['zloc'] > 0]\n",
    "#df_valid = df_valid[df_valid['zloc'] > 0]\n",
    "#df_test = df_test[df_test['zloc'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the class\n",
    "df_train['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encoding(dummy var)\n",
    "class_dummy = pd.get_dummies(df_train['class'])\n",
    "df_train = pd.concat([df_train, class_dummy], axis=1)\n",
    "\n",
    "class_dummy = pd.get_dummies(df_valid['class'])\n",
    "df_valid = pd.concat([df_valid, class_dummy], axis=1)\n",
    "\n",
    "class_dummy = pd.get_dummies(df_test['class'])\n",
    "df_test = pd.concat([df_test, class_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrVd\n",
    "#df_train = pd.concat([df_train, df_valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "le = LabelEncoder()\n",
    "train_label = le.fit_transform(df_train['class'])\n",
    "df_train['class_num'] = train_label\n",
    "\n",
    "valid_label = le.fit_transform(df_valid['class'])\n",
    "df_valid['class_num'] = valid_label\n",
    "\n",
    "test_label = le.fit_transform(df_test['class'])\n",
    "df_test['class_num'] = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the info of df\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = ['xmin','ymin','xmax','ymax','width', 'height','depth_mean_trim','depth_mean','depth_max','depth_median','Misc', 'bicycle', 'car', 'person', 'train', 'truck']\n",
    "val_length = len(variable)\n",
    "batch_sz = 24\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# train\n",
    "train_dataset = CustomDataset(df_train, variable, scaler=True, train=True, onehot=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_sz, shuffle=True)\n",
    "# train_sclaer\n",
    "scaler_train = train_dataset.scaler\n",
    "\n",
    "# valid\n",
    "valid_dataset = CustomDataset(df_valid, variable, True, train=scaler_train, onehot=False)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_sz, shuffle=True)\n",
    "\n",
    "# test\n",
    "test_dataset = CustomDataset(df_test, variable, True, train=scaler_train, onehot=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=len(df_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "# scaler\n",
    "dump(scaler_train, open('../model/lstm_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_length # 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look the dataset\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    print(batch[0])\n",
    "    print(batch[0].shape)\n",
    "    print(batch[0].dtype)\n",
    "    print(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_18WIN49vj6"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6SqWrYRLCdaO"
   },
   "outputs": [],
   "source": [
    "# zloc estimator model\n",
    "class Zloc_Estimaotor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True, bidirectional=False)\n",
    "        \n",
    "        #Layer\n",
    "        layersize=[306, 154, 76] # 294, 146, 72\n",
    "        layerlist= []\n",
    "        n_in=hidden_dim\n",
    "        for i in layersize:\n",
    "            layerlist.append(nn.Linear(n_in,i))\n",
    "            layerlist.append(nn.ReLU())\n",
    "            #layerlist.append(nn.BatchNorm1d(i))\n",
    "            #layerlist.append(nn.Dropout(0.1))\n",
    "            n_in=i           \n",
    "        layerlist.append(nn.Linear(layersize[-1],1))\n",
    "        #layerlist.append(nn.Sigmoid())\n",
    "        \n",
    "        self.fc=nn.Sequential(*layerlist)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, hn = self.rnn(x)\n",
    "        output = self.fc(out[:,-1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another model(differ version)\n",
    "class Zloc_Estimaotor_s(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Layer\n",
    "        layersize=[32,64,128,256,128,64,32]\n",
    "        layerlist= []\n",
    "        n_in=input_dim\n",
    "        for i in layersize:\n",
    "            layerlist.append(nn.Linear(n_in,i))\n",
    "            layerlist.append(nn.ReLU())\n",
    "            #layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(0.1))\n",
    "            n_in=i           \n",
    "        layerlist.append(nn.Linear(layersize[-1],1))\n",
    "        #layerlist.append(nn.Sigmoid())\n",
    "        \n",
    "        self.fc=nn.Sequential(*layerlist)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #out, hn = self.rnn(x)\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make  variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.init as init\n",
    "#def weight_init(m):\n",
    "#    if isinstance(m, nn.Linear): # nn.Linear에 있는 가중치에만 적용\n",
    "#        init.kaiming_uniform_(m.weight.data) # He initialization\n",
    "\n",
    "# variable \n",
    "input_dim = val_length\n",
    "hidden_dim = 612 # 612\n",
    "layer_dim = 3\n",
    "        \n",
    "model = Zloc_Estimaotor(input_dim, hidden_dim, layer_dim)\n",
    "#model = Zloc_Estimaotor_s(input_dim)\n",
    "#model.apply(weight_init)\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.5,\n",
    "                                                       patience = 10,\n",
    "                                                       mode='min', # 우리는 낮아지는 값을 기대\n",
    "                                                       verbose=True,\n",
    "                                                       min_lr=5e-5)\n",
    "from early_stopping import EarlyStopping\n",
    "early_stopping = EarlyStopping(70, verbose=True)   \n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train parameters\n",
    "def count_parameter(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameter(model) # 5686657"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7pqhZ4a9y99"
   },
   "source": [
    "## Make Train, Valid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "def train(model, train_dataloader, idx_interval):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_rmse = 0\n",
    "    \n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inp = batch[0].reshape(len(batch[0]),1,-1)\n",
    "        \n",
    "        prediction = model(inp.to(device))\n",
    "        loss = loss_fn(prediction, batch[1].to(device)).cpu()\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        if idx % idx_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}] \\t Train Loss(MAE): {:.4f} \\t Train RMAE: {:.4f}\".format(epoch, batch_sz*(idx+1), \\\n",
    "                                                                            len(train_dataloader)*batch_sz, \\\n",
    "                                                                            loss.item(), np.sqrt(loss.item())))\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_rmse = np.sqrt(train_loss)\n",
    "        \n",
    "    return train_loss, train_rmse\n",
    "#return loss and trainrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval function\n",
    "def evaluate(model, valid_dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    valid_loss = 0\n",
    "    valid_rmse = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(valid_dataloader):\n",
    "            inp = batch[0].reshape(len(batch[0]),1,-1)\n",
    "            predictions = model(inp.to(device))\n",
    "            loss = loss_fn(predictions, batch[1].to(device)).cpu()\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "    valid_loss /= len(valid_dataloader)\n",
    "    valid_rmse = np.sqrt(valid_loss)\n",
    "    \n",
    "    return valid_loss,valid_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "Epoch = 1000\n",
    "best_mae = 99999\n",
    "best_train_mae = 99999\n",
    "\n",
    "train_mae_list = []\n",
    "valid_mae_list = []\n",
    "\n",
    "\n",
    "for epoch in range(1,(Epoch+1)):\n",
    "    train_mae, train_rmae = train(model, train_dataloader, 200)\n",
    "    valid_mae, valid_rmae = evaluate(model, valid_dataloader)\n",
    "\n",
    "    print(\"[Epoch: {} \\t Valid MAE: {:.4f}\".format(epoch, valid_mae))\n",
    "    print(\"[Epoch: {} \\t Train MAE: {:.4f}\".format(epoch, train_mae))\n",
    "    \n",
    "    scheduler.step(valid_mae)       \n",
    "    # Save model\n",
    "    if valid_mae < best_mae:\n",
    "        path = \"./weights/ODD_variable16.pth\"\n",
    "        torch.save(model.state_dict(), path) # 모델의 가중치만 저장 구조는 저장 x..?\n",
    "        best_mae = valid_mae\n",
    "        best_train_mae = train_mae\n",
    "        \n",
    "    train_mae_list.append(train_mae)\n",
    "    valid_mae_list.append(valid_mae)\n",
    "    \n",
    "    early_stopping(valid_mae, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train result of mae\n",
    "print('Valid best:',best_mae)\n",
    "print('Train best:',best_train_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(train_mae_list, ls='-', color='blue', label='train')\n",
    "ax1.set_ylim(0,5)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(valid_mae_list, ls='--', color='red', label='valid')\n",
    "ax2.set_ylim(0,5)\n",
    "\n",
    "ax1.set_title('MAE error')\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(train_mae_list, ls='-', color='blue', label='train')\n",
    "plt.title('MAE loss - train')\n",
    "plt.legend(loc='best', labels=['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(valid_mae_list, ls='-', color='red', label='train')\n",
    "plt.title('MAE loss - valid')\n",
    "plt.legend(loc='best', labels=['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights\n",
    "model = Zloc_Estimaotor(input_dim, hidden_dim,layer_dim)\n",
    "model.load_state_dict(torch.load('./weights/ODD_variable16.pth'))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict value\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=len(df_train), shuffle=False)\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    train_pred = batch[0]\n",
    "predict_zloc = model(train_pred.reshape(-1,1,input_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the result\n",
    "df_train['predict'] = predict_zloc.cpu().detach().numpy()\n",
    "df_train[['zloc','predict']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate\n",
    "import numpy as np\n",
    "abs0 = np.abs(df_train.zloc-df_train.predict)\n",
    "abs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae\n",
    "sum(abs0/len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse\n",
    "np.mean(np.square(df_train['zloc']-df_train['predict']))**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "func = np.sum(np.abs((df_train.predict - df_train.zloc))/(df_train.predict))\n",
    "men = func/len(df_train)\n",
    "1-men"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid set\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=len(df_train), shuffle=False)\n",
    "for idx, batch in enumerate(valid_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    valid_pred = batch[0]\n",
    "predict_zloc = model(valid_pred.reshape(-1,1,input_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate valid\n",
    "df_valid['predict'] = predict_zloc.cpu().detach().numpy()\n",
    "df_valid[['zloc','predict']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs0 = np.abs(df_valid.zloc-df_valid.predict)\n",
    "abs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae\n",
    "sum(abs0/len(df_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse\n",
    "np.mean(np.square(df_valid['zloc']-df_valid['predict']))**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "func = np.sum(np.abs((df_valid.predict - df_valid.zloc))/(df_valid.predict))\n",
    "men = func/len(df_valid)\n",
    "1-men"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse, test_rmse = evaluate(model, test_dataloader)\n",
    "print('Test MAE: {:4f} \\t Test RMAE: {:4f}'.format(test_mse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look dataset\n",
    "for idx, batch in enumerate(test_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    test_pred = batch[0]\n",
    "predict_zloc = model(test_pred.reshape(-1,1,input_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['predict'] = predict_zloc.cpu().detach().numpy()\n",
    "df_test[['zloc','predict']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "abs0 = np.abs(df_test.zloc-df_test.predict)\n",
    "abs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae\n",
    "sum(abs0/len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rmse\n",
    "np.mean(np.square(df_test['zloc']-df_test['predict']))**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "func = np.sum(np.abs((df_test.predict - df_test.zloc))/(df_test.predict))\n",
    "men = func/len(df_test)\n",
    "1-men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object에 따라서 정확도 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.DataFrame(columns=['type','RMSE','MAE','Accuracy'])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truck\n",
    "truck = df_test['class']=='truck'\n",
    "df_truck = df_test[truck]\n",
    "\n",
    "# mae\n",
    "abs0 = np.abs(df_truck.zloc-df_truck.predict)\n",
    "print(sum(abs0/len(df_truck))) # 1.8629\n",
    "      \n",
    "# rmse \n",
    "print(np.mean(np.square(df_truck['zloc']-df_truck['predict']))**(1/2)) # 3.2170\n",
    "\n",
    "# accuracy\n",
    "func = np.sum(np.abs((df_truck.predict - df_truck.zloc))/(df_truck.predict))\n",
    "men = func/len(df_truck)\n",
    "print(1-men) # 0.9376\n",
    "\n",
    "matrix.loc[0,'type'] = 'truck'\n",
    "matrix.loc[0,'RMSE'] = round(np.mean(np.square(df_truck['zloc']-df_truck['predict']))**(1/2),4)\n",
    "matrix.loc[0,'MAE'] = round(sum(abs0/len(df_truck)),4)\n",
    "matrix.loc[0,'Accuracy'] = round(1-men,4)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car\n",
    "car = df_test['class']=='car'\n",
    "df_car = df_test[car]\n",
    "\n",
    "# mae\n",
    "abs0 = np.abs(df_car.zloc-df_car.predict)\n",
    "print(sum(abs0/len(df_car))) # 1.2531\n",
    "      \n",
    "# rmse \n",
    "print(np.mean(np.square(df_car['zloc']-df_car['predict']))**(1/2)) # 2.2713\n",
    "\n",
    "# accuracy\n",
    "func = np.sum(np.abs((df_car.predict - df_car.zloc))/(df_car.predict))\n",
    "men = func/len(df_car)\n",
    "print(1-men) # 0.9519\n",
    "\n",
    "matrix.loc[1,'type'] = 'car'\n",
    "matrix.loc[1,'RMSE'] = round(np.mean(np.square(df_car['zloc']-df_car['predict']))**(1/2),4)\n",
    "matrix.loc[1,'MAE'] = round(sum(abs0/len(df_car)),4)\n",
    "matrix.loc[1,'Accuracy'] = round(1-men,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# person\n",
    "person = df_test['class']=='person'\n",
    "df_person = df_test[person]\n",
    "\n",
    "# mae\n",
    "abs0 = np.abs(df_person.zloc-df_person.predict)\n",
    "print(sum(abs0/len(df_person))) # 0.7012\n",
    "      \n",
    "# rmse \n",
    "print(np.mean(np.square(df_person['zloc']-df_person['predict']))**(1/2)) # 1.2880\n",
    "\n",
    "# accuracy\n",
    "func = np.sum(np.abs((df_person.predict - df_person.zloc))/(df_person.predict))\n",
    "men = func/len(df_person)\n",
    "print(1-men) # 0.9529\n",
    "\n",
    "matrix.loc[2,'type'] = 'person'\n",
    "matrix.loc[2,'RMSE'] = round(np.mean(np.square(df_person['zloc']-df_person['predict']))**(1/2),4)\n",
    "matrix.loc[2,'MAE'] = round(sum(abs0/len(df_person)),4)\n",
    "matrix.loc[2,'Accuracy'] = round(1-men,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train = df_test['class']=='train'\n",
    "df_train = df_test[train] \n",
    "\n",
    "# mae\n",
    "abs0 = np.abs(df_train.zloc-df_train.predict)\n",
    "print(sum(abs0/len(df_train)))  # 1.6821\n",
    "      \n",
    "# rmse \n",
    "print(np.mean(np.square(df_train['zloc']-df_train['predict']))**(1/2)) # 2.3989\n",
    "\n",
    "# accuracy\n",
    "func = np.sum(np.abs((df_train.predict - df_train.zloc))/(df_train.predict))\n",
    "men = func/len(df_train)\n",
    "print(1-men) # 0.8611\n",
    "\n",
    "matrix.loc[3,'type'] = 'train'\n",
    "matrix.loc[3,'RMSE'] = round(np.mean(np.square(df_train['zloc']-df_train['predict']))**(1/2),4)\n",
    "matrix.loc[3,'MAE'] = round(sum(abs0/len(df_train)),4)\n",
    "matrix.loc[3,'Accuracy'] = round(1-men,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc\n",
    "misc = df_test['class']=='Misc'\n",
    "df_misc = df_test[misc] \n",
    "\n",
    "# mae\n",
    "abs0 = np.abs(df_misc.zloc-df_misc.predict)\n",
    "print(sum(abs0/len(df_misc)))  # 1.2972\n",
    "      \n",
    "# rmse \n",
    "print(np.mean(np.square(df_misc['zloc']-df_misc['predict']))**(1/2)) # 1.7389\n",
    "\n",
    "# accuracy\n",
    "func = np.sum(np.abs((df_misc.predict - df_misc.zloc))/(df_misc.predict))\n",
    "men = func/len(df_misc)\n",
    "print(1-men) # 0.9384\n",
    "\n",
    "matrix.loc[4,'type'] = 'Misc'\n",
    "matrix.loc[4,'RMSE'] = round(np.mean(np.square(df_misc['zloc']-df_misc['predict']))**(1/2),4)\n",
    "matrix.loc[4,'MAE'] = round(sum(abs0/len(df_misc)),4)\n",
    "matrix.loc[4,'Accuracy'] = round(1-men,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BICYCLE\n",
    "bicycle = df_test['class']=='bicycle'\n",
    "df_bicycle = df_test[bicycle] \n",
    "\n",
    "# mae\n",
    "abs0 = np.abs(df_bicycle.zloc-df_bicycle.predict)\n",
    "print(sum(abs0/len(df_bicycle)))  # 1.0336\n",
    "      \n",
    "# rmse \n",
    "print(np.mean(np.square(df_bicycle['zloc']-df_bicycle['predict']))**(1/2)) # 1.1845\n",
    "\n",
    "# accuracy\n",
    "func = np.sum(np.abs((df_bicycle.predict - df_bicycle.zloc))/(df_bicycle.predict))\n",
    "men = func/len(df_bicycle)\n",
    "print(1-men) # 0.9392\n",
    "\n",
    "matrix.loc[5,'type'] = 'bicycle'\n",
    "matrix.loc[5,'RMSE'] = round(np.mean(np.square(df_bicycle['zloc']-df_bicycle['predict']))**(1/2),4)\n",
    "matrix.loc[5,'MAE'] = round(sum(abs0/len(df_bicycle)),4)\n",
    "matrix.loc[5,'Accuracy'] = round(1-men,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.set_index('type', inplace=True)\n",
    "matrix.loc[['Misc','bicycle','car','person','train','truck'],['RMSE','MAE','Accuracy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다른 논문을 바탕으로 metric 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame(index=['LSTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abs Relative difference (Abs Rel)\n",
    "Abs_rel = np.sum(np.abs(df_test.predict - df_test.zloc)/df_test.zloc)/len(df_test)\n",
    "print('Abs_rel', Abs_rel) \n",
    "performance['Abs_rel'] = round(Abs_rel,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Squa_rel = np.sum((df_test.predict - df_test.zloc)**2/df_test.zloc)/len(df_test)\n",
    "print('Squa_rel:',Squa_rel) \n",
    "performance['Squa_rel'] = round(Squa_rel,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_log = np.sum(np.sqrt(((np.log(df_test.predict)-np.log(df_test.zloc))**2))/len(df_test))\n",
    "print('RMSE_log', RMSE_log)\n",
    "performance['RMSE_log'] = round(RMSE_log,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(delta):\n",
    "    percentage = 0\n",
    "    for i in range(len(df_test)):\n",
    "        max_value = max(df_test.loc[i,'zloc']/df_test.loc[i,'predict'], \\\n",
    "                        df_test.loc[i,'predict']/df_test.loc[i,'zloc'])\n",
    "        \n",
    "        if max_value < delta:\n",
    "            percentage += 1\n",
    "    return percentage/len(df_test)\n",
    "\n",
    "percentage_1 = round(threshold(1.25),3)\n",
    "percentage_2 = round(threshold(1.25**2),3)\n",
    "percentage_3 = round(threshold(1.25**3),3)\n",
    "print('Delta 1.25', percentage_1)\n",
    "print('Delta 1.25^2', percentage_2)\n",
    "print('Delta 1.25^3', percentage_3)\n",
    "\n",
    "\n",
    "performance['delta_1.25'] = round(percentage_1,3)\n",
    "performance['delta_1.25^2'] = round(percentage_2,3)\n",
    "performance['delta_1.25^3'] = round(percentage_3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구간 나눠서 정확도 계산해보기\n",
    "## Divide by distance range and calculate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = df_test[df_test['zloc']<=10]\n",
    "func1 = np.sum(np.abs((first.predict - first.zloc))/(first.predict))\n",
    "men1 = func1/len(first)\n",
    "1-men1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_test['zloc']>=10) & (df_test['zloc']<20)\n",
    "second = df_test[mask]\n",
    "func2 = np.sum(np.abs((second.predict - second.zloc))/(second.predict))\n",
    "men2 = func2/len(second)\n",
    "1-men2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_test['zloc']>=20) & (df_test['zloc']<30)\n",
    "third = df_test[mask]\n",
    "func3 = np.sum(np.abs((third.predict - third.zloc))/(third.predict))\n",
    "men3 = func3/len(third)\n",
    "1-men3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_test['zloc']>=30) & (df_test['zloc']<40)\n",
    "fourth = df_test[mask]\n",
    "func4 = np.sum(np.abs((fourth.predict - fourth.zloc))/(fourth.predict))\n",
    "men4 = func4/len(fourth)\n",
    "1-men4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_test['zloc']>=40) & (df_test['zloc']<50)\n",
    "fifth = df_test[mask]\n",
    "func5 = np.sum(np.abs((fifth.predict - fifth.zloc))/(fifth.predict))\n",
    "men5 = func5/len(fifth)\n",
    "1-men5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_test['zloc']>=50) & (df_test['zloc']<60)\n",
    "sixth = df_test[mask]\n",
    "func6 = np.sum(np.abs((sixth.predict - sixth.zloc))/(sixth.predict))\n",
    "men6 = func6/len(sixth)\n",
    "1-men6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_test['zloc']>=60) & (df_test['zloc']<70)\n",
    "seventh = df_test[mask]\n",
    "func7 = np.sum(np.abs((seventh.predict - seventh.zloc))/(seventh.predict))\n",
    "men7 = func7/len(seventh)\n",
    "1-men7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "for i in range(1,12):\n",
    "    mask = (df_test['zloc']<i*10) & (df_test['zloc'] >= (i-1)*10)\n",
    "    data = df_test[mask]\n",
    "    value = np.sum(np.abs((data.predict - data.zloc))/(data.predict))\n",
    "    output = value/len(data)\n",
    "    acc_list.append(1-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind='scatter', x='zloc', y='depth_mean', marker='o', alpha=0.3, s=50, figsize=(20,10), color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind='scatter', x='predict', y='zloc', marker='o', alpha=0.3, s=50, figsize=(10,10), color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.plot(kind='scatter', x='predict', y='zloc', marker='o', alpha=0.3, s=50, figsize=(10,10), color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.plot(kind='scatter', x='predict', y='zloc', marker='o', alpha=0.3, s=50, figsize=(10,10), color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3GgQX9wAHsY2zHAbVwAG/",
   "name": "DistanceEstimator.ipynb",
   "provenance": [
    {
     "file_id": "1WN5OSA-TXiMkTLDr9xyt2F7Z_Hd16-b4",
     "timestamp": 1649567852353
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
